{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc44a54",
   "metadata": {},
   "source": [
    "# ðŸ’¡Bank Loan Default Risk Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c7cb3",
   "metadata": {},
   "source": [
    "## ðŸ¥‡Approach\n",
    "- Individual analysis of Previous Data frame\n",
    "- Individual analysis of Application Data frame\n",
    "- Analysis of MERGED Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495c846",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "### ðŸŽ§Data understanding\n",
    "- Importing various libraries\n",
    "- Read the data\n",
    "- Analyze the shape\n",
    "- Analyze the data type\n",
    "\n",
    "### âœ‚Data Cleaning and Manipulation\n",
    "- Check for null value\n",
    "- Check for null percentage if required\n",
    "- Deal with null values.----->Either drop the columns or impute the missing value.\n",
    "\n",
    "### ðŸ›’Structuring\n",
    "- Check for number of unique value in each column\n",
    "- Clubbing the columns in similar bucket depending on its nature\n",
    "  - Categorical\n",
    "  - Continuous \n",
    "  - Unique ID type\n",
    "  \n",
    "### ðŸ”§Data analysis\n",
    "- Performed univariate and Bivariate analysis on variables.\n",
    "- Pearson's Correlation Coefficent.\n",
    "\n",
    "### ðŸ–‡Merge the Data frame via Inner Join\n",
    "- Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d408f",
   "metadata": {},
   "source": [
    "##### ðŸ’¼Main Variables used in the Assignment\n",
    "- df = Previous _application data set is stored in df\n",
    "- df1 = Application data set is stored in df1\n",
    "- categoricaldf = Lists of categorical columns in df\n",
    "- continuousdf = Lists of continuous(Numeric) columns in df\n",
    "- idnodf = Lists of unique identifiers columns in df\n",
    "- categoricald1f = Lists of categorical columns in df\n",
    "- continuousdf1 = Lists of continuous(Numeric) columns in df\n",
    "- idnodf1 = Lists of unique identifiers columns in df\n",
    "- Defaulter_df1 = Store defaulter of Current application\n",
    "- Non_defaulter_df1 = Store Non defaulter of Current application\n",
    "- Defaulter = Store defaulter of Merged data frame\n",
    "- Non_defaulter = Store Non defaulter of Merged data frame\n",
    "##### All other variables which are not mentioned above and used in the code are described in comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6e7dc",
   "metadata": {},
   "source": [
    "### User defined function used in EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1837a",
   "metadata": {},
   "source": [
    "1. convert_to_percentage()\n",
    "    - The function is used to convert the count value on axis in countplot to their respective percentage value without hue parameter in it.\n",
    "2. convert_to_percentage_hue()\n",
    "    - The function is used to convert the count value on axis in countplot to their respective percentage value with hue parameter in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.This func is called when hue parameter is not used in count plot (univariate analysis is done)\n",
    "# x is the column which is passed ,step is the no. of division of the y axis\n",
    "def convert_to_percentage(x,step=10):\n",
    "    upper_l=x.value_counts().max() # max value in colunm to properly use area of graph \n",
    "    total_l=len(x) #tatal count in the column to find the percentage\n",
    "    # Dividing the y axis depending on the value of step default value=10\n",
    "    ticks=np.arange(0,upper_l,upper_l//step)\n",
    "    labels=[\"{}%\".format(i*100//total_l)for i in ticks] # Changing counts to it's percentage\n",
    "    return (plt.yticks(ticks,labels))\n",
    "\n",
    "# 2.This  func is called when hue parameter is used in count plot\n",
    "# All variables are same as above\n",
    "def convert_to_percentage_hue(upper_l,total_l,step=10):\n",
    "    ticks=np.arange(0,upper_l,upper_l//step)\n",
    "    labels=[\"{}%\".format(i*100//total_l)for i in ticks]\n",
    "    return (plt.yticks(ticks,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0289a",
   "metadata": {},
   "source": [
    "#### 3.Creating a user defined function top10_Corr() to find top 10 Pearson Correlation Coefficient\n",
    " - Concepts used in the creating top10_Corr()\n",
    "   - Finding the pearson coefficent matrix\n",
    "   - Dropping ID columns.\n",
    "   - Deleting the duplicate pairs from the matrix\n",
    "   - We can either retain the lower or the upper triangle values.\n",
    "     - Retaining the upper triangle values\n",
    "   - Converting rest to Nan so that unique pairs exists and converting the matrix to 1-D array.\n",
    "   - Droping the NaN values\n",
    "   - Sorting the 1-D array (Correlation coefficents)\n",
    "   - Plotting and printing top 10 correlatiopn pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_Corr(y):\n",
    "    corr_matrix=y.corr(method=\"pearson\") # Finding the pearson coefficent matrix.\n",
    "    \n",
    "    \n",
    "    if (\"SK_ID_PREV\") in(y.columns):\n",
    "        corr_matrix.drop(columns=[\"SK_ID_CURR\",\"SK_ID_PREV\"],inplace=True)# droping the column\n",
    "        corr_matrix.drop(labels=[\"SK_ID_CURR\",\"SK_ID_PREV\"],inplace=True) # droping the rows\n",
    "        \n",
    "    elif (\"SK_ID_CURR_Current\") in(y.columns):\n",
    "        corr_matrix.drop(columns=[\"SK_ID_CURR\",\"SK_ID_PREV\",\"TARGET\"],inplace=True)# droping the column\n",
    "        corr_matrix.drop(labels=[\"SK_ID_CURR\",\"SK_ID_PREV\",\"TARGET\"],inplace=True) # droping the rows\n",
    "        \n",
    "    else:\n",
    "        corr_matrix.drop(columns=[\"SK_ID_CURR\",\"TARGET\"],inplace=True)# droping the column\n",
    "        corr_matrix.drop(labels=[\"SK_ID_CURR\",\"TARGET\"],inplace=True) # droping the rows\n",
    "        \n",
    "        \n",
    "# Retaining the upper triangle values, converting rest to Nan so that unique pairs exists and converting the matrix to 1-D array.\n",
    "    corr_matrix_uptri=corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool)).unstack()\n",
    "    \n",
    "\n",
    "# Droping the NaN values.\n",
    "    corr_matrix_uptri.dropna(inplace=True)\n",
    "\n",
    "# Sorting the 1-D array (Correlation coefficents) and showing the Top 10 Correlation coefficents.\n",
    "    corr_matrix_unstack=corr_matrix_uptri.sort_values(ascending=False)\n",
    "    \n",
    "# Collecting top10\n",
    "    top10=corr_matrix_unstack.head(10)\n",
    "# Converting to the data frame\n",
    "    top10=top10.reset_index()\n",
    "# Reseting the columns name to some meaning name.\n",
    "    top10.rename(columns={\"level_0\":\"column_1\",\"level_1\":\"column_2\",0:\"correlation\"},inplace=True)\n",
    "     \n",
    "# Plotting just for visulization\n",
    "    def top10_plot(x):\n",
    "        x.plot()\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(\"Top10 correlation graph\")\n",
    "        plt.show()\n",
    "       \n",
    "    return(top10,top10_plot(top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f0134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np,matplotlib.pyplot as plt,seaborn as sns\n",
    "# warning library is imported to ignore the warning in the code\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafe7b3",
   "metadata": {},
   "source": [
    "# Previous _application\n",
    "\n",
    "ðŸ“™***Previous _application data set contains information about the clients' previous loan data.It contains the data on whether the previous application has been Approved,Cancelled,Refused or Unused Offer.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c412f26d",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f25cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read previous_application csv in variable df.\n",
    "df=pd.read_csv(\"previous_application.csv\")\n",
    "\n",
    "# Changing the theme just for asthectic purpose.\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "df.head() # Top 5  rows will be displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db78d09",
   "metadata": {},
   "source": [
    "#### ðŸ‘€Getting an idea about the previous_application data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebcaee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analyze the shape of the data set\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ea42b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyze data type and null value presence in each column.\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910b518",
   "metadata": {},
   "source": [
    "#### ðŸŽ¯ Trying to figure out ,what to do with the null values in the data set if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16449c00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for the null values count in each column \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666c4b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check for the null percentage in each column to better take a call.\n",
    "round(df.isnull().sum()/df.shape[0],3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1b8b4",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ad98c",
   "metadata": {},
   "source": [
    "#### Dealing with the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d16fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Just drop the columns with more than 40% of null values\n",
    "df.drop([\"AMT_DOWN_PAYMENT\",\"RATE_DOWN_PAYMENT\",\"RATE_INTEREST_PRIMARY\",\"RATE_INTEREST_PRIVILEGED\",\n",
    "        \"NAME_TYPE_SUITE\",\"DAYS_FIRST_DRAWING\",\"DAYS_FIRST_DUE\",\"DAYS_LAST_DUE_1ST_VERSION\",\n",
    "        \"DAYS_LAST_DUE\",\"DAYS_TERMINATION\",\"NFLAG_INSURED_ON_APPROVAL\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c50ca77",
   "metadata": {},
   "source": [
    "#### Let's Impute the continuous variable missing value in each column now with their median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec447c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fillna() is used to impute NaN value with median for numeric columns.\n",
    "\n",
    "df.AMT_ANNUITY.fillna(df.AMT_ANNUITY.median(),inplace=True)\n",
    "\n",
    "df.AMT_GOODS_PRICE.fillna(df.AMT_GOODS_PRICE.median(),inplace=True)\n",
    "\n",
    "df.CNT_PAYMENT.fillna(df.CNT_PAYMENT.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95ecaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fillna() is used to impute NaN value with mode for categorical columns.\n",
    "\n",
    "df.PRODUCT_COMBINATION.fillna(df.PRODUCT_COMBINATION.mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27823aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Only 1 NaN value present in AMT_CREDIT so just dropped it.\n",
    "\n",
    "df=df[~df.AMT_CREDIT.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30609d37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ace607",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1206a",
   "metadata": {},
   "source": [
    "#### ðŸ’¡From the above matrix it can be clearly understood that \n",
    "- There is a huge difference in the max and 75th percentile of AMT_APPLICATION , AMT_CREDIT , AMT_GOODS_PRICE , CNT_PAYMENT ,etc which is a clear indication of the outliers.\n",
    "- Also some negative value have occured in few columns.\n",
    "##### We will deal with them in further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05679461",
   "metadata": {},
   "source": [
    "## ðŸ›’Structuring (Clubbing the columns in bins of similar nature).\n",
    "\n",
    "#### Trying to figure out the nature of each column and thus clubbing similar nature columns in lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fedd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking for the unique values in each column\n",
    "for i in df.columns:\n",
    "    print(i,\"->\",df[i].nunique(),df[i].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c613e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913e8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categoricaldf=[\"NAME_CONTRACT_TYPE\",\"WEEKDAY_APPR_PROCESS_START\",\"HOUR_APPR_PROCESS_START\",\n",
    "             \"FLAG_LAST_APPL_PER_CONTRACT\",\"NFLAG_LAST_APPL_IN_DAY\",\"NAME_CASH_LOAN_PURPOSE\",\n",
    "             \"NAME_CONTRACT_STATUS\",\"NAME_PAYMENT_TYPE\",\"CODE_REJECT_REASON\",\"NAME_CLIENT_TYPE\",\n",
    "             \"NAME_GOODS_CATEGORY\",\"NAME_PORTFOLIO\",\"NAME_PRODUCT_TYPE\",\"CHANNEL_TYPE\",\n",
    "             \"NAME_SELLER_INDUSTRY\",\"NAME_YIELD_GROUP\",\"PRODUCT_COMBINATION\"]\n",
    "continuousdf=[\"AMT_ANNUITY\",\"AMT_APPLICATION\",\"AMT_CREDIT\",\"AMT_GOODS_PRICE\",\"DAYS_DECISION\",\n",
    "            \"SELLERPLACE_AREA\",\"CNT_PAYMENT\"]\n",
    "idnodf=[\"SK_ID_PREV\",\"SK_ID_CURR\"]\n",
    "# Just doing a sanity check on total numbers of columns if I have missed any.\n",
    "len(categoricaldf)+len(continuousdf)+len(idnodf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271947a",
   "metadata": {},
   "source": [
    "# Continuous Variable Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bd0a5",
   "metadata": {},
   "source": [
    "## Univariate Analysis to deal with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820d74e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's plot two types of plot for better understanding.\n",
    "for i in continuousdf:\n",
    "    print(i)\n",
    "    plt.figure(figsize=[15,4]) #Increasing the size of the plots\n",
    "    \n",
    "    plt.subplot(121) # First plot code\n",
    "    sns.boxplot(df[i])\n",
    "    \n",
    "    plt.subplot(122) # Second plot code\n",
    "    sns.distplot(df[i])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358e634",
   "metadata": {},
   "source": [
    "#### Points to be collected from above plots-\n",
    "- The above graphs are the strong proof of the Outliers presence.\n",
    "- From the DAYS_DECISION boxplot it can be clearly visualized that the negative day is somewhat logically not sound so we will convert it to positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d60014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correcting the negative values in DAYS_DECISION,SELLERPLACE_AREA columns.\n",
    "\n",
    "df.DAYS_DECISION=df.DAYS_DECISION.abs()\n",
    "\n",
    "df.SELLERPLACE_AREA=df.SELLERPLACE_AREA.abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801022f2",
   "metadata": {},
   "source": [
    "#### Outliers Found in Continous Variable\n",
    "- Fixing Continous Variable Outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89d510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Capping and flooring the outliers so that justice can be done to the analysis.\n",
    "for i in continuousdf:\n",
    "    \n",
    "    q1=np.percentile(df[i],25) # Finding the 25th percentile\n",
    "    q3=np.percentile(df[i],75) # Finding the 75th percentile\n",
    "    \n",
    "    iqr=q3-q1 # Finding Inter Quatile Range\n",
    "    \n",
    "    uw=q3+1.5*iqr # Finding the upper whisker limit\n",
    "    lw=q1-1.5*iqr # Finding the lower whisker limit\n",
    "    \n",
    "    df[i]=np.where(df[i]<lw,lw,df[i]) # replacing the lower boundary outliers with the lower whisker value\n",
    "    df[i]=np.where(df[i]>uw,uw,df[i]) # replacing the upper boundary outliers with the upper whisker value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7b682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "for i in continuousdf:\n",
    "    print(i)\n",
    "    plt.figure(figsize=[11,4]) #Increasing the size of the plots\n",
    "    \n",
    "    plt.subplot(121) # First plot code\n",
    "    sns.boxplot(df[i])\n",
    "    \n",
    "    plt.subplot(122) # Second plot code\n",
    "    sns.distplot(df[i])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7f4dd",
   "metadata": {},
   "source": [
    "# Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee44c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's  plot two continuous variables.\n",
    "\n",
    "for i in continuousdf: # Automating all the continuous variables pair scatterplot\n",
    "    for j in continuousdf:\n",
    "        if i!=j: # Condition to avoid same variable on x and y axis\n",
    "            \n",
    "            print(i,\"VS\",j)\n",
    "            sns.scatterplot(df[i],df[j])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "(top10_Corr(df)) # Top10 previous application Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2b5a4",
   "metadata": {},
   "source": [
    "# Categorical Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b41a5",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5422c96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in categoricaldf:# Automating all the categorical variables countplot\n",
    "    print(i)\n",
    "    \n",
    "    plt.figure(figsize=[9,6])\n",
    "    sns.countplot(df[i])\n",
    "    convert_to_percentage(df[i])\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760efc88",
   "metadata": {},
   "source": [
    "#### Assumption\n",
    "- In NAME_CONTRACT_TYPE ,NAME_CLIENT_TYPE columns I am assuming XNA as missing category and imputing it with the column's mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b75de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imputing NAME_CONTRACT_TYPE with mode\n",
    "df.NAME_CONTRACT_TYPE=df.NAME_CONTRACT_TYPE.replace(\"XNA\",df.NAME_CONTRACT_TYPE.mode()[0])\n",
    "# Imputing NAME_CLIENT_TYPE with mode\n",
    "df.NAME_CLIENT_TYPE=df.NAME_CLIENT_TYPE.replace(\"XNA\",df.NAME_CLIENT_TYPE.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8bdd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ok ,let's correct the Cancelled spelling\n",
    "df.NAME_CONTRACT_STATUS=df.NAME_CONTRACT_STATUS.apply(lambda x:x.replace(\"Canceled\",\"Cancelled\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fb605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "df.NAME_CONTRACT_STATUS.value_counts().plot.pie(autopct=\"%0.01f%%\")\n",
    "plt.title(\"Previous CONTRACT STATUS\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ddd65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "df.NAME_CLIENT_TYPE.value_counts().plot.pie(autopct=\"%0.01f%%\",explode=[0,0.1,0])\n",
    "plt.title(\"Overall Previous CLIENT TYPE\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n",
    "print(\"The above plot reveals that previously the most loan applications were from repeater.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171959e2",
   "metadata": {},
   "source": [
    "##### We need to have keen eye on refused client when they come next time for loan.So let's store the refused client information in seprate variable for future use if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6cb53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# storing Refused Client details in seprate variable.\n",
    "RefusedClient=df[df.NAME_CONTRACT_STATUS==\"Refused\"]\n",
    "\n",
    "RefusedClient.NAME_CLIENT_TYPE.value_counts().plot.pie(autopct=\"%0.01f%%\")\n",
    "plt.title(\"Refused Client Type \")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n",
    "print(\"ðŸ™„Among the refused application previously maximum were repeater.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5407b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(RefusedClient[RefusedClient.NAME_CLIENT_TYPE==\"Repeater\"][\"CODE_REJECT_REASON\"].value_counts(normalize=True)*100).plot.barh()\n",
    "plt.title(\"Refused Repeater CLIENT's Reason and its count\\n\")\n",
    "plt.xlabel(\"Percentage\")\n",
    "plt.show()\n",
    "print(\"The reason for previously refused application of repeater clients are maximum due to HC.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa5c92e",
   "metadata": {},
   "source": [
    "#### Assumption\n",
    "- As the meaning of XAP,XNA in CODE_REJECT_REASON column is not clearly mentioned so I am assuming them as a valid category for this column..\n",
    "- I have decided not to impute them as there presence are huge in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34121b",
   "metadata": {},
   "source": [
    "### ðŸFew points which have poped out from the above plots for previous data set are-\n",
    "- Cash and Consumer loans seem to be two most popular category asked by clients.\n",
    "- The maximum numbers of the applications were filled during 9am to 4pm.\n",
    "- Purpose for most of the loans are for XAP and XNA.\n",
    "- Most of the clients applications seem to be Approved.\n",
    "- Payment method that client chose to pay for the previous application is maximum for Cash through the bank.\n",
    "- Maximum previous application rejection reasons was XAP.\n",
    "- Most of the clients applying seems to be Repeater.\n",
    "- Top 5 goods which clients applied in the previous applications are...\n",
    "  - XNA                       \n",
    "  - Mobile                      \n",
    "  - Consumer Electronics        \n",
    "  - Computers                   \n",
    "  - Audio/Video\n",
    "- Maximum previous application  was for POS followed by Cash.\n",
    "- Credit and cash offices seem to be popular channel of acquiring the clients followed by country-wide.\n",
    "- Top 3 industry of the seller are...\n",
    "  - XNA                    \n",
    "  - Consumer electronics\n",
    "  - Connectivity \n",
    "- Most of the grouped interest lies in the category other than low_action.\n",
    "- The reason for previously refused application are of repeater client is maximum due to HC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa69d6",
   "metadata": {},
   "source": [
    "# Categorical-Continuous Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c7fd5",
   "metadata": {},
   "source": [
    "#### Let's try to analyze the interdependence between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72477e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in categoricaldf: # Automating categorical- continuous plot\n",
    "    for j in continuousdf:\n",
    "        \n",
    "        print(i,\"Vs\",j)\n",
    "        plt.figure(figsize=[15,4])\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        sns.boxplot(df[i],df[j])# Plot 1\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        sns.barplot(df[i],df[j],ci=None,estimator=np.median)# plot 2\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680368a1",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- The average amount ask for cash loan is comparetively greater as a result average annuity amount is also increasing for the same.\n",
    "- The highest median annuites amounts ie., greater than 25000 are for-----\n",
    "   - Buying a new car/home\n",
    "   - Buying a used car\n",
    "   - Building a house\n",
    "   - Buying a garage\n",
    "   - Buisness developements\n",
    "   - Payments of other loans\n",
    "- A trend is seen that higher the loan amount highter is the term of credit,ie., more time to pay back.\n",
    "_ A very interesting insight is that clients with higher ask are refused or in other words most of the refused clients ask were greater than 15 lakh.\n",
    "- Repeater seems to have greater annunity amount than the new clients even though the application amounts are approximately same.\n",
    "- Bank seems to give more amount to repeater clients than initally asked for but in case of new clients it is not the pattern.\n",
    "- House construction goods category is having huge amount annuity.\n",
    "- Clients asked maximun amount for car portfolio.\n",
    "- Most of the application's amounts are from Car dealer and corporate sales channel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed221ca3",
   "metadata": {},
   "source": [
    "#### ðŸ›´ Let's move to the other data set for better picture about the analysis. So we will leave the present dataset for the timing and switch to other for more clearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be0443",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621dba40",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Application_data\n",
    "\n",
    "ðŸ“™***Application_data csv contains all the information of the clients at the time of application(Data is about if client has payment difficulties)***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb4200",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e40aa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Read application_data csv in variable df1.\n",
    "\n",
    "df1=pd.read_csv(\"application_data.csv\")\n",
    "pd.set_option(\"display.max_columns\",122) # For viewing  all columns in the data set\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb62d3",
   "metadata": {},
   "source": [
    "#### ðŸ‘€Getting an idea about the application_data csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f60cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analyze the shape of the data set\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164f699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17f3c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyze data type of each column \n",
    "\n",
    "df1.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b0824",
   "metadata": {},
   "source": [
    "## ðŸ—‘Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b1fab",
   "metadata": {},
   "source": [
    "#### ðŸŽ¯ Trying to figure out ,what to do with the null values in the data set if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74da5ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code to see all the rows in the next line code's O/P\n",
    "pd.set_option(\"display.max_rows\",122) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eddaed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for the null values in each column \n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865888a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for the percentage of null values in each column and storing the column name with null % in variable p.\n",
    "null_percentage=round(df1.isnull().sum()/df1.shape[0],3)*100\n",
    "null_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92be3d",
   "metadata": {},
   "source": [
    " #### Droping the columns with >= 40% of missing values in each column.\n",
    " - As we have around 50 columns to drop so instead of droping manually, a good approach is to filter the columns to be dropped in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18111ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extract columns with missing values >=40% .\n",
    "null_percentage[null_percentage>=40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee75bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the lists of missing column stored in (p[p>=40].index)\n",
    "df1.drop(columns=null_percentage[null_percentage>=40].index).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363dd1b1",
   "metadata": {},
   "source": [
    "#### Now as I am sure that the above code dropped the required columns perfectly by looking at the shape of the data set,So now I will add \"inplace = True\" Clause in the above Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc6216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.drop(columns=null_percentage[null_percentage>=40].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a93da",
   "metadata": {},
   "source": [
    "#### As a sanity check let's again check for the columns with >=40% of missing value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b620e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "round(df1.isnull().mean()*100,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51db19a",
   "metadata": {},
   "source": [
    "#### We will just leave missing values with 13.5% of last 6 columns from AMT_REQ_CREDIT_BUREAU_HOUR to AMT_REQ_CREDIT_BUREAU_YEAR as these will remain untouched in our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b2baa",
   "metadata": {},
   "source": [
    "#### ðŸ˜ŽYup good to go now we will fix rest of the missing values in other columns. Let's fix them individually now.\n",
    "\n",
    "#### First let's drop the rows with very less missing values i.e.,<=1% associated with respective Columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64be876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1=df1[~df1.AMT_ANNUITY.isnull()]\n",
    "df1=df1[~df1.CNT_FAM_MEMBERS.isnull()]\n",
    "df1=df1[~df1.DAYS_LAST_PHONE_CHANGE.isnull()]\n",
    "df1=df1[~df1.NAME_TYPE_SUITE.isnull()]\n",
    "df1=df1[~df1.EXT_SOURCE_2.isnull()]\n",
    "df1=df1[~df1.OBS_30_CNT_SOCIAL_CIRCLE.isnull()]\n",
    "df1=df1[~df1.DEF_30_CNT_SOCIAL_CIRCLE.isnull()]\n",
    "df1=df1[~df1.OBS_60_CNT_SOCIAL_CIRCLE.isnull()]\n",
    "df1=df1[~df1.DEF_60_CNT_SOCIAL_CIRCLE.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d1f56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculating the unique value in each column to determine the nature of the columns.\n",
    "\n",
    "for i in df1.columns:\n",
    "    print(i,\"-\",df1[i].nunique(),\"-\",df1[i].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df0790",
   "metadata": {},
   "source": [
    "## ðŸ›’Structuring (Clubbing the columns in bins of similar nature).\n",
    "\n",
    "#### Trying to figure out the nature of each column and thus clubbing similar nature columns in lists.\n",
    "\n",
    "#### We will club similar nature columns and the just take the columns which are important in our analysis from the understanding of data dictionary for this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018be316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We will keep TARGET column seprate from this clubbing in any list.\n",
    "\n",
    "categoricaldf1=[\"NAME_CONTRACT_TYPE\",\"CODE_GENDER\",\"FLAG_OWN_CAR\",\"FLAG_OWN_REALTY\",\"CNT_CHILDREN\",\"NAME_TYPE_SUITE\",\n",
    "                \"NAME_INCOME_TYPE\",\"NAME_EDUCATION_TYPE\",\"NAME_FAMILY_STATUS\",\"NAME_HOUSING_TYPE\",\"FLAG_MOBIL\",\"FLAG_EMP_PHONE\",\n",
    "                \"FLAG_WORK_PHONE\",\"FLAG_CONT_MOBILE\",\"FLAG_PHONE\",\"FLAG_EMAIL\",\"OCCUPATION_TYPE\",\"CNT_FAM_MEMBERS\",\n",
    "                \"REGION_RATING_CLIENT\",\"REGION_RATING_CLIENT_W_CITY\",\"WEEKDAY_APPR_PROCESS_START\",\"REG_REGION_NOT_LIVE_REGION\",\n",
    "               \"REG_REGION_NOT_WORK_REGION\",\"LIVE_REGION_NOT_WORK_REGION\",\"REG_CITY_NOT_LIVE_CITY\",\"REG_CITY_NOT_WORK_CITY\",\n",
    "                \"LIVE_CITY_NOT_WORK_CITY\",\"ORGANIZATION_TYPE\",\"DEF_30_CNT_SOCIAL_CIRCLE\",\"DEF_60_CNT_SOCIAL_CIRCLE\"]\n",
    "\n",
    "continuousdf1=[\"AMT_INCOME_TOTAL\",\"AMT_CREDIT\",\"AMT_ANNUITY\",\"AMT_GOODS_PRICE\",\"REGION_POPULATION_RELATIVE\",\"DAYS_BIRTH\",\n",
    "               \"DAYS_EMPLOYED\",\"DAYS_REGISTRATION\",\"DAYS_ID_PUBLISH\",\"HOUR_APPR_PROCESS_START\",\"OBS_30_CNT_SOCIAL_CIRCLE\",\n",
    "               \"OBS_60_CNT_SOCIAL_CIRCLE\",\"DAYS_LAST_PHONE_CHANGE\"]\n",
    "\n",
    "idnodf1=[\"SK_ID_CURR\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62c8d6",
   "metadata": {},
   "source": [
    "## Data understanding and converting it's type to suitable dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5460ac1",
   "metadata": {},
   "source": [
    "#### Categorical Variable understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categoricaldf1:\n",
    "    print(i)\n",
    "    print(df1[i].unique(),df1[i].dtype,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b1d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing the data type of required columns.\n",
    "\n",
    "df1.CNT_FAM_MEMBERS=df1.CNT_FAM_MEMBERS.astype(int)\n",
    "\n",
    "df1.DEF_30_CNT_SOCIAL_CIRCLE=df1.DEF_30_CNT_SOCIAL_CIRCLE.astype(int)\n",
    "\n",
    "df1.DEF_60_CNT_SOCIAL_CIRCLE=df1.DEF_60_CNT_SOCIAL_CIRCLE.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009deabe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop XNA rows from CODE_GENDER column as it is very small in number.\n",
    "df1=df1[~(df1.CODE_GENDER==\"XNA\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070fbf10",
   "metadata": {},
   "source": [
    "##### In OCCUPATION_TYPE column we have NAN value Let's check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425071d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.OCCUPATION_TYPE.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2322fa18",
   "metadata": {},
   "source": [
    "##### So we have 31% missing value which is relatively high so in this column so we will just add a new category \"Missing\" for the NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d720e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.OCCUPATION_TYPE.fillna(\"Missing\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888a005",
   "metadata": {},
   "source": [
    "# Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39337a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df1.TARGET.value_counts(normalize=True)*100).plot.pie(autopct=\"%0.1f%%\")\n",
    "print(\"The below distribution of TARGET column says that the Non defaulters are very high in number ie.,most of  the clients pay back the loan.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91207525",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df1.TARGET,hue=df1.CODE_GENDER)\n",
    "print(\"The below distribution of TARGET column says that the Non defaulters are very high in number ie.,most of the clients pay back the loan.\")\n",
    "convert_to_percentage(df1.TARGET) # Calling the user defined func\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfe41b",
   "metadata": {},
   "source": [
    "#### ðŸ˜ŽOk now all categorical related columns have been successfully processed for the analysis Let's move to Continuous Variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83de85b",
   "metadata": {},
   "source": [
    "## Continuous variable understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57daf4b6",
   "metadata": {},
   "source": [
    "### Univariate Analysis  to deal with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969cdd2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ploting for the continuous variable.\n",
    "for i in continuousdf1:\n",
    "    print(i)\n",
    "    \n",
    "    plt.figure(figsize=[15,4])# Increasing the plot size\n",
    "    \n",
    "    plt.subplot(121)  # plot 1 code\n",
    "    sns.boxplot(df1[i])\n",
    "    \n",
    "    plt.subplot(122)  #Plot 2 code\n",
    "    sns.distplot(df1[i])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019b11f",
   "metadata": {},
   "source": [
    "## ðŸ¤·â€â™‚ï¸Outliers and some data anamolies found!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45abfbb",
   "metadata": {},
   "source": [
    "### From the boxplot few more points have lighten upðŸ™„What can be done!!!!\n",
    "#### ðŸ‘€There are some anamolies as we can clearly see that some columns related to days and dates have some negative value which are not logical,so let's first correct it.\n",
    "##### ðŸ’¡ In order to convert the negative term we can either use the lambda () with apply or multiply the column by (-1) or simply we can use abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8037a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.DAYS_BIRTH=(df1.DAYS_BIRTH)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ac8c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.DAYS_REGISTRATION=df1.DAYS_REGISTRATION.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65bf6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.DAYS_ID_PUBLISH=df1.DAYS_ID_PUBLISH.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b641d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.DAYS_LAST_PHONE_CHANGE=df1.DAYS_LAST_PHONE_CHANGE.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7993d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.DAYS_EMPLOYED=df1.DAYS_EMPLOYED.abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32652cd8",
   "metadata": {},
   "source": [
    "#### Let's convert DAYS_BIRTH column from days to years in order to get the better picture and also change it's name to YEARS_BIRTH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84b909",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Converting age in days to age in years for better picture.\n",
    "\n",
    "df1.DAYS_BIRTH=df1.DAYS_BIRTH//365\n",
    "df1.rename(columns={\"DAYS_BIRTH\":\"YEARS_BIRTH\"},inplace=True) # Renaming column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc3c62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Sanity Check\n",
    "df1.YEARS_BIRTH.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba2f3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing the name of the column in continuousdf1 list as the age in days were converted to age in years.\n",
    "\n",
    "continuousdf1=list(map(lambda x: x.replace(\"DAYS_BIRTH\", \"YEARS_BIRTH\"),continuousdf1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35fefbc",
   "metadata": {},
   "source": [
    "#### Fixing Continous Variable Outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d3a59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Capping and flooring the outliers so that justice can be done to the analysis.\n",
    "\n",
    "for i in continuousdf1:\n",
    "    \n",
    "    q1=np.percentile(df1[i],25) # Finding the 25th percentile\n",
    "    q3=np.percentile(df1[i],75) # # Finding the 75th percentile\n",
    "    \n",
    "    iqr=q3-q1  # Inter Quantile Range\n",
    "    \n",
    "    uw=q3+1.5*iqr  # Upper whisker limit\n",
    "    lw=q1-1.5*iqr  # Lower whisker limit\n",
    "    \n",
    "    df1[i]=np.where(df1[i]<lw,lw,df1[i])# Imputing the outliers present beyond the lower boundary with the lower whisker value\n",
    "    df1[i]=np.where(df1[i]>uw,uw,df1[i])# # Imputing the outliers present beyond the upper boundary with the upper whisker value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8367b",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a92da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in continuousdf1:\n",
    "    print(i)\n",
    "    \n",
    "    plt.figure(figsize=[15,4])# Increasing the plot size\n",
    "    \n",
    "    plt.subplot(121)  # plot 1 code\n",
    "    sns.boxplot(df1[i])\n",
    "    \n",
    "    plt.subplot(122)  #Plot 2 code\n",
    "    sns.distplot(df1[i])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b1c3e",
   "metadata": {},
   "source": [
    "\n",
    "# Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc034e",
   "metadata": {},
   "source": [
    "## Continuous-Continuous Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079cc408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in continuousdf1:\n",
    "    for j in continuousdf1:\n",
    "        if i!=j: # Condition to avoid same variable  on both x and y axis\n",
    "            \n",
    "            print(i,\"Vs\",j)\n",
    "            sns.scatterplot(df1[i],df1[j],hue=df1.CODE_GENDER)\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c13d45",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Good pattern is seen between AMT_CREDIT Vs AMT_GOODS_PRICE which implies that for consumer loans , price of the goods asked is credited most of the time to the clients. \n",
    "  - Other point is that bank is not partial in terms of gender while giving the goods loan as spread of red     and blue dots are evenly plotted in the direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa43955",
   "metadata": {},
   "source": [
    "#### Top 10 correlations of df1 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484443a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(top10_Corr(df1)) # Top 10 Current application Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79f473",
   "metadata": {},
   "source": [
    "\n",
    "## Categorical Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb855440",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb1702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in categoricaldf1:\n",
    "    print(i)\n",
    "    plt.figure(figsize=[15,4])\n",
    "    sns.countplot(df1[i])\n",
    "    convert_to_percentage(df1[i])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1540fac2",
   "metadata": {},
   "source": [
    "### Let's jot down points from the above Univariate analysis\n",
    "- Most of the loan asked are of cash type.\n",
    "- Female seems to apply more for loan.\n",
    "- Most of the applicant does not own car.\n",
    "- Most of the applicant seems to have their own house.\n",
    "- Most of the applicants seems to have no children yet , this is just a early conclusion.\n",
    "- Most of the applicants were not accompained by anyone while applying for the loan.\n",
    "- Secondary/secondary special level education clients seems to be fairly high.\n",
    "- Married category is high.\n",
    "- Highest number of applicants seems to have 2 members in their family.\n",
    "- Business Entity Type 3 and 2 are maximum to apply.\n",
    "- Most of the clients for loan seems to be Laborer.\n",
    "- 73 % of clients are from 2nd rating Region and city."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5d194",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa118a",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Categorical-Categorical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54745499",
   "metadata": {},
   "source": [
    "#### Categorical Vs Gender Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954233a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in categoricaldf1:\n",
    "    if i!= \"CODE_GENDER\":\n",
    "        print(i)\n",
    "        sns.countplot(df1[i],hue=df1.CODE_GENDER)\n",
    "        upper_l=df1.groupby(i)[\"CODE_GENDER\"].value_counts().max()\n",
    "        total_l=df1.groupby(i)[\"CODE_GENDER\"].value_counts().sum()\n",
    "        convert_to_percentage_hue(upper_l,total_l) # Calling the user defined func to convert y label to %\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def14f47",
   "metadata": {},
   "source": [
    "#### Let's collect the points from above analysis\n",
    "- Among Pensioner female have applied more for loan.\n",
    "- Married clients are more attracted toward loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66625a39",
   "metadata": {},
   "source": [
    "### Categorical-Continuous Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280428a",
   "metadata": {},
   "source": [
    "#### Let's try to analyze the interdependence between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b29fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in categoricaldf1:\n",
    "    for j in continuousdf1:\n",
    "        \n",
    "        print(i,\"Vs\",j)\n",
    "        plt.figure(figsize=[15,4])\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        sns.boxplot(df1[i],df1[j])#Plot 1\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        sns.barplot(df1[i],df1[j],ci=None)#Plot 2\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2638a4",
   "metadata": {},
   "source": [
    "### In our further analysis we will analyze with respect to the Target Variable.\n",
    "-  So let's just club all the data on the basis of defaulter and non-defaulter and analyze the pattern between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0851a426",
   "metadata": {},
   "source": [
    "### Univariate Segmented Analysis with respect to Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627b1e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Storing Non defaulter data\n",
    "Non_defaulter_df1=df1[df1.TARGET==0]\n",
    "\n",
    "#Storing defaulter data\n",
    "Defaulter_df1=df1[df1.TARGET==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8b46f",
   "metadata": {},
   "source": [
    "### TARGET Variable (Defaulter Data VS Non Defaulter) analysis  Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ae02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in categoricaldf1:\n",
    "    if i!= \"CODE_GENDER\":\n",
    "        \n",
    "        plt.figure(figsize=[18,6])\n",
    "        print(i)\n",
    "        \n",
    "        plt.subplot(121) # Code for Plot 1\n",
    "        sns.countplot(Defaulter_df1[i],hue=df1.CODE_GENDER,order=Defaulter_df1[i].value_counts().index)\n",
    "        plt.title(\"Defaulter (1)\")\n",
    "        upper_l=Defaulter_df1.groupby(i)[\"CODE_GENDER\"].value_counts().max()\n",
    "        total_l=Defaulter_df1.groupby(i)[\"CODE_GENDER\"].value_counts().sum()\n",
    "        convert_to_percentage_hue(upper_l,total_l) # Func call to change value to percentage\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        plt.subplot(122) # Code for Plot 2\n",
    "        sns.countplot(Non_defaulter_df1[i],hue=df1.CODE_GENDER,order=Non_defaulter_df1[i].value_counts().index)\n",
    "        plt.title(\"Non defaulter (0)\")\n",
    "        upper_l=Non_defaulter_df1.groupby(i)[\"CODE_GENDER\"].value_counts().max()\n",
    "        total_l=Non_defaulter_df1.groupby(i)[\"CODE_GENDER\"].value_counts().sum()\n",
    "        convert_to_percentage_hue(upper_l,total_l)  # Func call to change value to percentage\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776dce0",
   "metadata": {},
   "source": [
    "### Let's jot down the new remarkable points if any from the above  analysis grouped by Gender(0 vs 1).\n",
    "- Female clients seems to have more defaulter.\n",
    "- Most of the defaulters own their house.\n",
    "- Majority of defaulters have no child.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951cb2ae",
   "metadata": {},
   "source": [
    "#### As ORGANIZATION_TYPE plot is not clearly visible so let's analyze it separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4cc7b",
   "metadata": {},
   "source": [
    "### ðŸ’¡Which ORGANIZATION TYPE seems to have more defaulters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bde0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18,6])\n",
    "\n",
    "sns.countplot(Defaulter_df1.ORGANIZATION_TYPE,order=Defaulter_df1.ORGANIZATION_TYPE.value_counts().index)\n",
    "plt.title(\"Defaulter (1)\")\n",
    "plt.ylabel(\"No.of Client %\")\n",
    "convert_to_percentage(Defaulter_df1.ORGANIZATION_TYPE)  # Calling the user defined func to convert y label to %\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.figure(figsize=[18,6])\n",
    "sns.countplot(Non_defaulter_df1.ORGANIZATION_TYPE,order=Non_defaulter_df1.ORGANIZATION_TYPE.value_counts().index)\n",
    "plt.title(\"Non defaulter (0)\")\n",
    "plt.ylabel(\"No.of Client %\")\n",
    "convert_to_percentage(Non_defaulter_df1.ORGANIZATION_TYPE) # Calling the user defined func to convert y label to %\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00902a8c",
   "metadata": {},
   "source": [
    "### Note\n",
    "- XNA category count is comparatively high and also it's meaning is not explained in the data frame  so I have not impuated it.\n",
    "\n",
    "#### Conclusion\n",
    "- Maximum clients are from \"Business Entity Type 3\" and most of the defaulters(25%) are also from this category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b193550",
   "metadata": {},
   "source": [
    "## ðŸ’¡ What is the effect of education vs income type on defaulters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851fee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18,6])\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.countplot(Defaulter_df1.NAME_INCOME_TYPE,hue=df1.NAME_EDUCATION_TYPE,order=Defaulter_df1.NAME_INCOME_TYPE.value_counts().index)\n",
    "plt.title(\"Defaulter (1)\")\n",
    "plt.ylabel(\"No.of Client %\")\n",
    "upper_l=Defaulter_df1.groupby(\"NAME_INCOME_TYPE\")[\"NAME_EDUCATION_TYPE\"].value_counts().max()\n",
    "total_l=Defaulter_df1.groupby(\"NAME_INCOME_TYPE\")[\"NAME_EDUCATION_TYPE\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l) # Calling the user defined func to convert y label to %\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend(loc=1)\n",
    "        \n",
    "plt.subplot(122)\n",
    "sns.countplot(Non_defaulter_df1.NAME_INCOME_TYPE,hue=df1.NAME_EDUCATION_TYPE,order=Non_defaulter_df1.NAME_INCOME_TYPE.value_counts().index)\n",
    "plt.title(\"Non defaulter (0)\")\n",
    "plt.ylabel(\"No.of Client %\")\n",
    "upper_l=Non_defaulter_df1.groupby(\"NAME_INCOME_TYPE\")[\"NAME_EDUCATION_TYPE\"].value_counts().max()\n",
    "total_l=Non_defaulter_df1.groupby(\"NAME_INCOME_TYPE\")[\"NAME_EDUCATION_TYPE\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l,15) # Calling the user defined func to convert y label to %\n",
    "plt.xticks(rotation=35)\n",
    "plt.legend(loc=1)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412460d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Conclusion\n",
    "- Approx 60 % of defaulter are from Working income type also a general is seen that secondary level education is doing more default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3811b69",
   "metadata": {},
   "source": [
    "# ðŸ”Merging of the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3286bc9",
   "metadata": {},
   "source": [
    "#### As our main aim is to find loan defaulter so it will be wise to merge the data frame via \"Inner Join\" as we will get know about the clients those who have previously applied and also currently want to apply for loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e5ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfmerge=pd.merge(left=df1,right=df,how=\"inner\",on=\"SK_ID_CURR\",suffixes=(\"_Current\",\"_Previous\"))\n",
    "dfmerge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a89e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "\n",
    "print(\"df1 \",df1.shape)\n",
    "print(\"df \",df.shape)\n",
    "print(\"dfmerge \",dfmerge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33c9f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfmerge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fba03c",
   "metadata": {},
   "source": [
    "Let's just drop the columns which will not be the part of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfef92e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfmerge.drop(columns=['EXT_SOURCE_2', 'EXT_SOURCE_3','FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "       'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
    "       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n",
    "       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21',],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4093ad",
   "metadata": {},
   "source": [
    "# ðŸŒ±Final Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2036fb",
   "metadata": {},
   "source": [
    "### ðŸŽ¯TARGET Variable (Defaulter Data VS Non Defaulter) analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae33f2",
   "metadata": {},
   "source": [
    "Yup good to go but before that we will bin few columns as per our requirements as we have not yet able to analyze based on age ,income so just give a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260e14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(dfmerge.YEARS_BIRTH)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca7ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfmerge[\"Age_Bucket\"]=pd.cut(x=dfmerge.YEARS_BIRTH,bins=[0,30,45,60,999],labels=[\"Young\",\"Adult\",\"Senior Adult\",\"Senior\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb019be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(dfmerge.AMT_INCOME_TOTAL)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c70d3",
   "metadata": {},
   "source": [
    "#### Let's bucket the income in 3 category as outliers are already dealt with we have less than 3,50,000 amount income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ee459",
   "metadata": {},
   "source": [
    "Let's bucket client income now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086de50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfmerge[\"Income_Bucket\"]=pd.cut(x=dfmerge.AMT_INCOME_TOTAL,bins=[0,150000,300000,100000000],labels=[\"Low\",\"Medium \",\"High\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a398f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfmerge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d407b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfmerge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496aefed",
   "metadata": {},
   "source": [
    "### ðŸ’¡Which loan type is in demand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc71f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.countplot(dfmerge.NAME_CONTRACT_TYPE_Current,hue=dfmerge.TARGET)\n",
    "plt.title(\"Current application\")\n",
    "plt.ylabel(\"No.of Client %\")\n",
    "\n",
    "# Calling func converting y labels to %\n",
    "upper_l=dfmerge.groupby(\"NAME_CONTRACT_TYPE_Current\")[\"TARGET\"].value_counts().max()\n",
    "total_l=dfmerge.groupby(\"NAME_CONTRACT_TYPE_Current\")[\"TARGET\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l) # Calling the user defined func to convert yticks to percentage\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.countplot(dfmerge.NAME_CONTRACT_TYPE_Previous,hue=dfmerge.TARGET)\n",
    "plt.title(\"Previous application\")\n",
    "plt.ylabel(\"No.of Client %\")\n",
    "\n",
    "# Calling func converting y labels to %\n",
    "upper_l=dfmerge.groupby(\"NAME_CONTRACT_TYPE_Previous\")[\"TARGET\"].value_counts().max()\n",
    "total_l=dfmerge.groupby(\"NAME_CONTRACT_TYPE_Previous\")[\"TARGET\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l) # Calling the user defined func to convert yticks to percentage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f009c35",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- The demand for cash loanhas increased abruptly from 44% to 92% compare to the previous data set while there is no demand for consumer loan i.e., decreased to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66c6ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Storing Non defaulter data\n",
    "Non_defaulter=dfmerge[dfmerge.TARGET==0]\n",
    "\n",
    "#Storing defaulter data\n",
    "Defaulter=dfmerge[dfmerge.TARGET==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbf9bf",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12591c5",
   "metadata": {},
   "source": [
    "### ðŸ’¡Which Income bucket people have more  defaulter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05def5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18,6])\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.countplot(Defaulter.Income_Bucket) # Defaulter Income plot\n",
    "plt.title(\"Defaulter (1)\")\n",
    "plt.ylabel(\"No. of client %\")\n",
    "convert_to_percentage(Defaulter.Income_Bucket)\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.countplot(Non_defaulter.Income_Bucket) # Non Defaulter Income plot\n",
    "plt.title(\"Non defaulter (0)\")\n",
    "plt.ylabel(\"No. of client %\")\n",
    "convert_to_percentage(Non_defaulter.Income_Bucket)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abdd38",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- The above graphs conclude that the person with  low and medium income tends to default more(about 47%) and this seems completely justified as   poor people miss the timely payment of installments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e123ab",
   "metadata": {},
   "source": [
    "### ðŸ’¡Which Age group people have more defaulters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e41b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18,6])\n",
    "\n",
    "plt.subplot(121)\n",
    "(Defaulter.Age_Bucket.value_counts(normalize=True)*100).plot.pie(autopct=\"%0.1f%%\")\n",
    "plt.title(\"Defaulter (1)\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.subplot(122)\n",
    "(Non_defaulter.Age_Bucket.value_counts(normalize=True)*100).plot.pie(autopct=\"%0.1f%%\")\n",
    "plt.title(\"Non defaulter (0)\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c6359",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- The graph states that the adult seems to have more default,it can be justified in a way that these group people are having more responsibilites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a2fe3",
   "metadata": {},
   "source": [
    "### ðŸ’¡What is the education level of most of the defaulter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d973224",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18,6])\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.countplot(Defaulter.NAME_EDUCATION_TYPE)# Defaulters' education information\n",
    "plt.xticks(rotation=30)\n",
    "convert_to_percentage(Defaulter.NAME_EDUCATION_TYPE) # Calling the user defined func to convert yticks to percentage\n",
    "plt.ylabel(\"No. of client %\")\n",
    "plt.title(\"Defaulter's education level\")\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.countplot(Defaulter.NAME_EDUCATION_TYPE,hue=Defaulter.CODE_GENDER) # Defaulters' education information Gender wise\n",
    "upper_l=Defaulter.groupby(\"NAME_EDUCATION_TYPE\")[\"CODE_GENDER\"].value_counts().max()\n",
    "total_l=Defaulter.groupby(\"NAME_EDUCATION_TYPE\")[\"CODE_GENDER\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l) # Calling the user defined func to convert yticks to percentage\n",
    "plt.title(\"Defaulter's education level gender wise\")\n",
    "plt.ylabel(\"No. of client %\")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144385e",
   "metadata": {},
   "source": [
    "### ðŸ’¡What is the education level of most of the defaulter Income Bucket wise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52752ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaulters' education information Gender wise\n",
    "sns.countplot(Defaulter.NAME_EDUCATION_TYPE,hue=Defaulter.Income_Bucket)\n",
    "\n",
    "upper_l=Defaulter.groupby(\"NAME_EDUCATION_TYPE\")[\"Income_Bucket\"].value_counts().max()\n",
    "total_l=Defaulter.groupby(\"NAME_EDUCATION_TYPE\")[\"Income_Bucket\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l) # Calling the user defined func to convert yticks to percentage\n",
    "\n",
    "plt.title(\"Defaulter's education level gender wise\")\n",
    "plt.ylabel(\"No. of client %\")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb9a15c",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Most of the defaulter(80 %) are from Secondary level of education ,infact here also female count is high.\n",
    "- Even from Secondary level 47 % are female.\n",
    "- Defaulter's count decreases with increase in their education level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b16172",
   "metadata": {},
   "source": [
    "### ðŸ’¡What is the family status of most of the defaulter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab29e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18,6])\n",
    "\n",
    "plt.subplot(121)\n",
    "Defaulter.NAME_FAMILY_STATUS.value_counts().plot.pie(autopct=\"%0.01f%%\")\n",
    "plt.title(\"Defaulter Family Status\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.countplot(Defaulter.NAME_FAMILY_STATUS,hue=Defaulter.Income_Bucket)\n",
    "\n",
    "\n",
    "upper_l=Defaulter.groupby(\"NAME_FAMILY_STATUS\")[\"Income_Bucket\"].value_counts().max()\n",
    "total_l=Defaulter.groupby(\"NAME_FAMILY_STATUS\")[\"Income_Bucket\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l) # Calling the user defined func to convert yticks to percentage\n",
    "plt.title(\"Defaulter Family Status Income Bucket wise\")\n",
    "plt.ylabel(\"No. of client %\")\n",
    "plt.xticks(rotation=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2513ce",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Married clients seem to do more default and most of them have either low or medium income ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ac7d9",
   "metadata": {},
   "source": [
    "### ðŸ’¡Which region seems to be having more default case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a2fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[9,4])\n",
    " # Plot for defaulters\n",
    "sns.distplot(Defaulter.REGION_POPULATION_RELATIVE,color=\"r\",label=\"Defaulter (1)\")\n",
    " # Plot for Non defaulters\n",
    "sns.distplot(Non_defaulter.REGION_POPULATION_RELATIVE,color=\"c\",label=\"Non defaulter (0)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc277f5d",
   "metadata": {},
   "source": [
    "#### Assumption \n",
    "- Cities have High population density\n",
    "- Villages have low population density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07cf588",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Though the pattern for both defaulter and non defaulter are same but point here is ,  maximium loan is taken by area with low population ie., by village people as cities' have high population density."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14687080",
   "metadata": {},
   "source": [
    "### ðŸ’¡What is the term (months) of credit  pattern seen for most of the defaulter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369328d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[9,4])\n",
    "\n",
    "sns.distplot(Defaulter.CNT_PAYMENT,color=\"r\",label=\"Defaulter (1)\") # Plot for defaulters\n",
    "\n",
    "sns.distplot(Non_defaulter.CNT_PAYMENT,color=\"c\",label=\"Non defaulter (0)\") # Plot for Non defaulters\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06167bf5",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Maximum defaulters previous term of credit lies in the range 10 to 15 months and few are from 25 month tenure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d771fab",
   "metadata": {},
   "source": [
    "\n",
    "### ðŸ’¡What can be said about GOODS LOAN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67268ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.distplot(dfmerge.AMT_GOODS_PRICE_Current,color=\"r\",label=\"Current\")\n",
    "sns.distplot(dfmerge.AMT_GOODS_PRICE_Previous,color=\"c\",label=\"Previous\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(222)\n",
    "sns.barplot(y=dfmerge.AMT_GOODS_PRICE_Current,color=\"r\",label=\"Current\")\n",
    "sns.barplot(y=dfmerge.AMT_GOODS_PRICE_Previous,color=\"c\",label=\"Previous\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27f961",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- The demand for goods loan is on increase both number and amount wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b5705",
   "metadata": {},
   "source": [
    "### ðŸ‘€If the demand is high for goods loan then risk is also high for the same,let's analyze it further!!!! and ðŸ’¡find the average spread ask from the defaulters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c5f466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "\n",
    "#Code for plot 1\n",
    "plt.subplot(221)\n",
    "sns.distplot(Defaulter.AMT_GOODS_PRICE_Current,color=\"r\",label=\"Defaulter\")\n",
    "sns.distplot(Non_defaulter.AMT_GOODS_PRICE_Current,color=\"c\",label=\"Non Defaulter\")\n",
    "plt.title(\"Current application\")\n",
    "plt.legend()\n",
    "\n",
    "#Code for plot 2\n",
    "plt.subplot(222)\n",
    "sns.distplot(Defaulter.AMT_GOODS_PRICE_Previous,color=\"r\",label=\"Defaulter\")\n",
    "sns.distplot(Non_defaulter.AMT_GOODS_PRICE_Previous,color=\"c\",label=\"Non Defaulter\")\n",
    "plt.title(\"Previous application\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d50cb",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- The defaulters ask this time,mainly for GOODS PRICE ranges from 2 to 5 lakh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6b542",
   "metadata": {},
   "source": [
    "### ðŸ’¡What is the spread of credit amount given by bank to it's client in compare to the previous credit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a4ee4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.distplot(Defaulter.AMT_CREDIT_Current,color=\"r\",label=\"Defaulter\")\n",
    "sns.distplot(Non_defaulter.AMT_CREDIT_Current,color=\"c\",label=\"Non Defaulter\")\n",
    "plt.title(\"Current application\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(222)\n",
    "sns.distplot(Defaulter.AMT_CREDIT_Previous,color=\"r\",label=\"Defaulter\")\n",
    "sns.distplot(Non_defaulter.AMT_CREDIT_Previous,color=\"c\",label=\"Non Defaulter\")\n",
    "plt.title(\"Previous application\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116e3e5",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- The distribution of current credit amount has increased greatly.\n",
    "- Earlier maximum credit given was around 5 lakh but this time it is around 17.5 lakh.\n",
    "- Earlier defaulters' credit amount were less than 1 lakh but this time most of the defaulters' lies in the range of 0-7.5 lakh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e7d9f",
   "metadata": {},
   "source": [
    "### ðŸ’¡What is the effect of the interest rate on the defaulters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0d61c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(Defaulter.NAME_YIELD_GROUP,hue=Defaulter.Income_Bucket,order=Defaulter.NAME_YIELD_GROUP.value_counts().index)\n",
    "plt.xticks(rotation=30)\n",
    "upper_l=Defaulter.groupby(\"NAME_YIELD_GROUP\")[\"Income_Bucket\"].value_counts().max()\n",
    "total_l=Defaulter.groupby(\"NAME_YIELD_GROUP\")[\"Income_Bucket\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l)\n",
    "plt.ylabel(\"No. of client %\")\n",
    "plt.title(\"Defaulter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6df3ae",
   "metadata": {},
   "source": [
    "### Note\n",
    "- I have not imputed the XNA in the above plot as it's meaning is not clearly mentioned in the data dictionary ,also it is huge in number so imputing it without having it's proper information will not bring justic to my analysis.  \n",
    "\n",
    "#### Conclusion\n",
    "- The loan with greater interest seems to default more so we can draw a conclusion that greater the interest rate higher is the risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b51b5a",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e5aa8",
   "metadata": {},
   "source": [
    "### ðŸ’¡Which Income Type People seems to cause more default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78832c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.barplot(Defaulter.NAME_INCOME_TYPE,Defaulter.AMT_INCOME_TOTAL,ci=None)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Defaulter\")\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.countplot(Defaulter.NAME_INCOME_TYPE,hue=Defaulter.Income_Bucket)\n",
    "plt.title(\"Defaulter Income Type\")\n",
    "plt.ylabel(\"No. of client %\")\n",
    "\n",
    "upper_l=Defaulter.groupby(\"NAME_INCOME_TYPE\")[\"Income_Bucket\"].value_counts().max()\n",
    "total_l=Defaulter.groupby(\"NAME_INCOME_TYPE\")[\"Income_Bucket\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598df38",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Persons with low income bucket seems to do more default\n",
    "- Working  category takes major loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e90180f",
   "metadata": {},
   "source": [
    "## ðŸ’¡Which Income type based on age seems to default more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b369310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.countplot(Defaulter.NAME_INCOME_TYPE,hue=Defaulter.Age_Bucket)\n",
    "plt.title(\"Defaulter\")\n",
    "plt.ylabel(\"No. of client %\")\n",
    "\n",
    "upper_l=Defaulter.groupby(\"NAME_INCOME_TYPE\")[\"Age_Bucket\"].value_counts().max()\n",
    "total_l=Defaulter.groupby(\"NAME_INCOME_TYPE\")[\"Age_Bucket\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l)\n",
    "\n",
    "plt.xticks(rotation=35)\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.barplot(Defaulter.NAME_INCOME_TYPE,Defaulter.AMT_INCOME_TOTAL,hue=Defaulter.Age_Bucket,ci=None)\n",
    "plt.title(\"Defaulter\")\n",
    "plt.xticks(rotation=35)\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f3832",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Working Adults seem to have more default case .\n",
    "- Average income of Commercial associate are  compartively greater than others.\n",
    "- Among defaulters senior are having higher average income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fa196",
   "metadata": {},
   "source": [
    "### ðŸ’¡ For how long  defaulters have been earning ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(Defaulter.AMT_INCOME_TOTAL,Defaulter.DAYS_EMPLOYED,hue=Defaulter.CODE_GENDER)\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe95d3",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Most of the defaulters income total is less than 2.5 lakh and most of them are working for about 10 years.\n",
    "- Most of the female defaulter has income less than 2 lakh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b0211",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Occupation with their Income type Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4755d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,6])\n",
    "\n",
    "sns.countplot(Defaulter.NAME_INCOME_TYPE,hue=Defaulter.OCCUPATION_TYPE)\n",
    "# Calling the user defined func to convert yticks to percentage\n",
    "upper_l=Defaulter.groupby(\"NAME_INCOME_TYPE\")[\"OCCUPATION_TYPE\"].value_counts().max()\n",
    "total_l=Defaulter.groupby(\"NAME_INCOME_TYPE\")[\"OCCUPATION_TYPE\"].value_counts().sum()\n",
    "convert_to_percentage_hue(upper_l,total_l) \n",
    "\n",
    "plt.ylabel(\"No. of client %\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.title(\"Defaulter's Occupation with their Income type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4329f",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- Working defaulter are the majority and among them Laborers are the higher defaulters.\n",
    "- Pensioner also consists of 12 % among defaulters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8311e",
   "metadata": {},
   "source": [
    "### Top 10 Defaulter Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5b67f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10_Corr(Defaulter) # top 10 defaulter correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2beb9",
   "metadata": {},
   "source": [
    "### Non Defaulter Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ecb45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10_Corr(Non_defaulter) # Top 10 Non defaulter correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c582e7fe",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "- In all the correlations there seems to be a strong relation between good price and amount credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8684ecd",
   "metadata": {},
   "source": [
    "# Final Conclusion (Defaulter Pattern )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671af8e4",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Bank should pay extra attention to following criteria whlie giving loan -\n",
    "- Loan Type - Cash loan\n",
    "- Gender - \"Female\" clients \n",
    "- Eucation Type - \"Secondary level\" of education (Higher the  Education lesser the  default)\n",
    "- Occupation Type - \"WORKING\" and also little focus on \"Commercial associates/Pensioner\" \n",
    "- INCOME Type - \"LABOURERS\"\n",
    "- Income Bucket - \"LOW/MEDIUM\"\n",
    "- Age Bucket - \"Adult\"\n",
    "- Interest charged by bank - Higher the rate charged greater the risk\n",
    "- Credit Amount - Most of the defaulters' lies in the range of 0-7.5 lakh\n",
    "- Family status - \"Married\"\n",
    "- Organization Type - Bussiness Type 3 /Self Employeed\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
